{"expireTime":9007200867804455000,"key":"gatsby-plugin-mdx-entire-payload-0fc1380a57f4dbcd4bd142bc3d7c31b0-","val":{"mdast":{"type":"root","children":[{"type":"import","value":"import { CopyBlock, dracula } from \"react-code-blocks\";","position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":1,"column":56,"offset":55},"indent":[]}},{"type":"heading","depth":1,"children":[{"type":"text","value":"Detecting Fake news","position":{"start":{"line":3,"column":3,"offset":59},"end":{"line":3,"column":22,"offset":78},"indent":[]}}],"position":{"start":{"line":3,"column":1,"offset":57},"end":{"line":3,"column":22,"offset":78},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Data has become the center of today’s’ businesses. In this modern world, 1.7 megaBytes data is generated per second. Many technologies have evolved to use this massive data for a better world. Machine learning is one of them and today we plan to use it to detect fake news. ","position":{"start":{"line":5,"column":1,"offset":80},"end":{"line":5,"column":275,"offset":354},"indent":[]}}],"position":{"start":{"line":5,"column":1,"offset":80},"end":{"line":5,"column":275,"offset":354},"indent":[]}},{"type":"paragraph","children":[{"type":"image","title":null,"url":"fake.jpg","alt":"fake news","position":{"start":{"line":7,"column":1,"offset":356},"end":{"line":7,"column":23,"offset":378},"indent":[]}}],"position":{"start":{"line":7,"column":1,"offset":356},"end":{"line":7,"column":23,"offset":378},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"What exactly is fake news?","position":{"start":{"line":9,"column":4,"offset":383},"end":{"line":9,"column":30,"offset":409},"indent":[]}}],"position":{"start":{"line":9,"column":1,"offset":380},"end":{"line":9,"column":30,"offset":409},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Fake news is pieces of misinformation that are often incorporated to mislead people. Fake news is easy to spread as it carries no verification evidence.  This is often done to further or impose certain ideas and is often achieved with political agendas.","position":{"start":{"line":11,"column":1,"offset":411},"end":{"line":11,"column":254,"offset":664},"indent":[]}}],"position":{"start":{"line":11,"column":1,"offset":411},"end":{"line":11,"column":254,"offset":664},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"How do we plan to solve it?","position":{"start":{"line":13,"column":4,"offset":669},"end":{"line":13,"column":31,"offset":696},"indent":[]}}],"position":{"start":{"line":13,"column":1,"offset":666},"end":{"line":13,"column":31,"offset":696},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"This project is broken down into 5 steps, namely:","position":{"start":{"line":15,"column":1,"offset":698},"end":{"line":15,"column":50,"offset":747},"indent":[]}}],"position":{"start":{"line":15,"column":1,"offset":698},"end":{"line":15,"column":50,"offset":747},"indent":[]}},{"type":"list","ordered":true,"start":1,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Loading the data","position":{"start":{"line":17,"column":4,"offset":752},"end":{"line":17,"column":20,"offset":768},"indent":[]}}],"position":{"start":{"line":17,"column":4,"offset":752},"end":{"line":17,"column":20,"offset":768},"indent":[]}}],"position":{"start":{"line":17,"column":1,"offset":749},"end":{"line":17,"column":20,"offset":768},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Format the data","position":{"start":{"line":18,"column":4,"offset":772},"end":{"line":18,"column":19,"offset":787},"indent":[]}}],"position":{"start":{"line":18,"column":4,"offset":772},"end":{"line":18,"column":19,"offset":787},"indent":[]}}],"position":{"start":{"line":18,"column":1,"offset":769},"end":{"line":18,"column":19,"offset":787},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Tokenize the data","position":{"start":{"line":19,"column":4,"offset":791},"end":{"line":19,"column":21,"offset":808},"indent":[]}}],"position":{"start":{"line":19,"column":4,"offset":791},"end":{"line":19,"column":21,"offset":808},"indent":[]}}],"position":{"start":{"line":19,"column":1,"offset":788},"end":{"line":19,"column":21,"offset":808},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Build our model ","position":{"start":{"line":20,"column":4,"offset":812},"end":{"line":20,"column":20,"offset":828},"indent":[]}}],"position":{"start":{"line":20,"column":4,"offset":812},"end":{"line":20,"column":20,"offset":828},"indent":[]}}],"position":{"start":{"line":20,"column":1,"offset":809},"end":{"line":20,"column":20,"offset":828},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Train multiple models","position":{"start":{"line":21,"column":4,"offset":832},"end":{"line":21,"column":25,"offset":853},"indent":[]}}],"position":{"start":{"line":21,"column":4,"offset":832},"end":{"line":21,"column":25,"offset":853},"indent":[]}}],"position":{"start":{"line":21,"column":1,"offset":829},"end":{"line":21,"column":25,"offset":853},"indent":[]}}],"position":{"start":{"line":17,"column":1,"offset":749},"end":{"line":21,"column":25,"offset":853},"indent":[1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Let us get started on detecting the fake news!","position":{"start":{"line":23,"column":1,"offset":855},"end":{"line":23,"column":47,"offset":901},"indent":[]}}],"position":{"start":{"line":23,"column":1,"offset":855},"end":{"line":23,"column":47,"offset":901},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Loading the Data","position":{"start":{"line":26,"column":5,"offset":908},"end":{"line":26,"column":21,"offset":924},"indent":[]}}],"position":{"start":{"line":26,"column":1,"offset":904},"end":{"line":26,"column":21,"offset":924},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"I have used the “Fake or Real News Dataset” from Kaggle. < link here>.\nThe dataset comprises 2 csv files, namely fake and true. Both the files are available on kaggle for download. ","position":{"start":{"line":28,"column":1,"offset":926},"end":{"line":29,"column":111,"offset":1107},"indent":[1]}}],"position":{"start":{"line":28,"column":1,"offset":926},"end":{"line":29,"column":111,"offset":1107},"indent":[1]}},{"type":"jsx","value":"<br />\n<CopyBlock\nlanguage={\"python\"}\ntext={ ` df_fake = pd.read_csv('Fake.csv')\ndf_true = pd.read_csv('True.csv') `}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":32,"column":1,"offset":1110},"end":{"line":40,"column":13,"offset":1297},"indent":[1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"The initial step would be to merge both the files to have one single file for both train and testing. However, before merging we need to add labels to it. We consider 1 for True and 0 for False. We introduce a new column called ‘class’.","position":{"start":{"line":42,"column":1,"offset":1299},"end":{"line":42,"column":237,"offset":1535},"indent":[]}}],"position":{"start":{"line":42,"column":1,"offset":1299},"end":{"line":42,"column":237,"offset":1535},"indent":[]}},{"type":"jsx","value":"<br />\n<CopyBlock\nlanguage={\"python\"}\ntext={ `df_fake['class'] = 0\ndf_true['class'] = 1  `}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":44,"column":1,"offset":1537},"end":{"line":52,"column":13,"offset":1698},"indent":[1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"After doing that, we simply merge both the files.","position":{"start":{"line":54,"column":1,"offset":1700},"end":{"line":54,"column":50,"offset":1749},"indent":[]}}],"position":{"start":{"line":54,"column":1,"offset":1700},"end":{"line":54,"column":50,"offset":1749},"indent":[]}},{"type":"jsx","value":"<br />\n<CopyBlock\nlanguage={\"python\"}\ntext={ `df_merge = pd.concat([df_fake, df_true], axis =0 ) `}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":56,"column":1,"offset":1751},"end":{"line":63,"column":13,"offset":1920},"indent":[1,1,1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Format the data","position":{"start":{"line":66,"column":5,"offset":1927},"end":{"line":66,"column":20,"offset":1942},"indent":[]}}],"position":{"start":{"line":66,"column":1,"offset":1923},"end":{"line":66,"column":20,"offset":1942},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Data preprocessing is a vital step to build a good model. Let us see the columns we have : ","position":{"start":{"line":68,"column":1,"offset":1944},"end":{"line":68,"column":92,"offset":2035},"indent":[]}}],"position":{"start":{"line":68,"column":1,"offset":1944},"end":{"line":68,"column":92,"offset":2035},"indent":[]}},{"type":"jsx","value":"<br />\n<CopyBlock\nlanguage={\"python\"}\ntext={ `df_merge.columns `}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":70,"column":1,"offset":2037},"end":{"line":77,"column":13,"offset":2172},"indent":[1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"For simplicity, we remove the columns \"title\", \"subject\",\"date\" and retain the text and class column for further processing.","position":{"start":{"line":79,"column":1,"offset":2174},"end":{"line":79,"column":125,"offset":2298},"indent":[]}}],"position":{"start":{"line":79,"column":1,"offset":2174},"end":{"line":79,"column":125,"offset":2298},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `df = df_merge.drop([\"title\", \"subject\",\"date\"], axis = 1) `}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":81,"column":1,"offset":2300},"end":{"line":87,"column":13,"offset":2469},"indent":[1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Next we check for any null values,","position":{"start":{"line":89,"column":1,"offset":2471},"end":{"line":89,"column":35,"offset":2505},"indent":[]}}],"position":{"start":{"line":89,"column":1,"offset":2471},"end":{"line":89,"column":35,"offset":2505},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `df.isnull().sum() `}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":91,"column":1,"offset":2507},"end":{"line":97,"column":13,"offset":2636},"indent":[1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Great, we have no null values. Now let us replace the index column and have a cleaner dataset.","position":{"start":{"line":100,"column":1,"offset":2639},"end":{"line":100,"column":95,"offset":2733},"indent":[]}}],"position":{"start":{"line":100,"column":1,"offset":2639},"end":{"line":100,"column":95,"offset":2733},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `df.reset_index(inplace = True)\ndf.drop([\"index\"], axis = 1, inplace = True)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":103,"column":1,"offset":2736},"end":{"line":110,"column":13,"offset":2922},"indent":[1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"I have defined a function wordopt below that performs basic regex operations on the text columns and modifies text on the following parameters:","position":{"start":{"line":113,"column":1,"offset":2925},"end":{"line":113,"column":144,"offset":3068},"indent":[]}}],"position":{"start":{"line":113,"column":1,"offset":2925},"end":{"line":113,"column":144,"offset":3068},"indent":[]}},{"type":"list","ordered":true,"start":1,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Removes URLs and website links.","position":{"start":{"line":116,"column":4,"offset":3074},"end":{"line":116,"column":35,"offset":3105},"indent":[]}}],"position":{"start":{"line":116,"column":4,"offset":3074},"end":{"line":116,"column":35,"offset":3105},"indent":[]}}],"position":{"start":{"line":116,"column":1,"offset":3071},"end":{"line":116,"column":35,"offset":3105},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Removes unwanted spacings.","position":{"start":{"line":117,"column":4,"offset":3109},"end":{"line":117,"column":30,"offset":3135},"indent":[]}}],"position":{"start":{"line":117,"column":4,"offset":3109},"end":{"line":117,"column":30,"offset":3135},"indent":[]}}],"position":{"start":{"line":117,"column":1,"offset":3106},"end":{"line":117,"column":30,"offset":3135},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Replaces punctuations with a single space.","position":{"start":{"line":118,"column":4,"offset":3139},"end":{"line":118,"column":46,"offset":3181},"indent":[]}}],"position":{"start":{"line":118,"column":4,"offset":3139},"end":{"line":118,"column":46,"offset":3181},"indent":[]}}],"position":{"start":{"line":118,"column":1,"offset":3136},"end":{"line":118,"column":46,"offset":3181},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Removes line spacings.","position":{"start":{"line":119,"column":4,"offset":3185},"end":{"line":119,"column":26,"offset":3207},"indent":[]}}],"position":{"start":{"line":119,"column":4,"offset":3185},"end":{"line":119,"column":26,"offset":3207},"indent":[]}}],"position":{"start":{"line":119,"column":1,"offset":3182},"end":{"line":119,"column":26,"offset":3207},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Converts words in its lowercase.","position":{"start":{"line":120,"column":4,"offset":3211},"end":{"line":120,"column":36,"offset":3243},"indent":[]}}],"position":{"start":{"line":120,"column":4,"offset":3211},"end":{"line":120,"column":36,"offset":3243},"indent":[]}}],"position":{"start":{"line":120,"column":1,"offset":3208},"end":{"line":120,"column":36,"offset":3243},"indent":[]}}],"position":{"start":{"line":116,"column":1,"offset":3071},"end":{"line":120,"column":36,"offset":3243},"indent":[1,1,1,1]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `def wordopt(text):\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub(\"\\\\W\",\" \",text) \n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)    \n    return text `}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":124,"column":1,"offset":3247},"end":{"line":139,"column":13,"offset":3729},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"This function is then applied to our text column, ","position":{"start":{"line":142,"column":1,"offset":3732},"end":{"line":142,"column":51,"offset":3782},"indent":[]}}],"position":{"start":{"line":142,"column":1,"offset":3732},"end":{"line":142,"column":51,"offset":3782},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `df[\"text\"] = df[\"text\"].apply(wordopt)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":144,"column":1,"offset":3784},"end":{"line":150,"column":13,"offset":3933},"indent":[1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Before performing tokenization, we have one final step to do. Split the dataset into test and train. We consider having a 70 - 30 split.","position":{"start":{"line":152,"column":1,"offset":3935},"end":{"line":152,"column":137,"offset":4071},"indent":[]}}],"position":{"start":{"line":152,"column":1,"offset":3935},"end":{"line":152,"column":137,"offset":4071},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `x = df['text']\ny = df['class']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3) `}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":155,"column":1,"offset":4074},"end":{"line":163,"column":13,"offset":4289},"indent":[1,1,1,1,1,1,1,1]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Tokenize the data","position":{"start":{"line":166,"column":5,"offset":4296},"end":{"line":166,"column":22,"offset":4313},"indent":[]}}],"position":{"start":{"line":166,"column":1,"offset":4292},"end":{"line":166,"column":22,"offset":4313},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"We use TF IDF to convert the text input into vectors. The explanation of TF IDF is out of scope for this blog, however, you may refer to get a deeper understanding. We use sklearn library to perform the steps.","position":{"start":{"line":168,"column":1,"offset":4315},"end":{"line":168,"column":210,"offset":4524},"indent":[]}}],"position":{"start":{"line":168,"column":1,"offset":4315},"end":{"line":168,"column":210,"offset":4524},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `from sklearn.feature_extraction.text import TfidfVectorizer\n \nvectorization = TfidfVectorizer()\nxv_train = vectorization.fit_transform(x_train)\nxv_test = vectorization.transform(x_test) `}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":170,"column":1,"offset":4526},"end":{"line":180,"column":13,"offset":4823},"indent":[1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Now, that we have the tokenized data, let’s build our first model.","position":{"start":{"line":183,"column":1,"offset":4826},"end":{"line":183,"column":67,"offset":4892},"indent":[]}}],"position":{"start":{"line":183,"column":1,"offset":4826},"end":{"line":183,"column":67,"offset":4892},"indent":[]}},{"type":"heading","depth":3,"children":[{"type":"text","value":"Building the Model","position":{"start":{"line":185,"column":5,"offset":4898},"end":{"line":185,"column":23,"offset":4916},"indent":[]}}],"position":{"start":{"line":185,"column":1,"offset":4894},"end":{"line":185,"column":23,"offset":4916},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"We plan to build 4 different models and then compare them to choose the best one.","position":{"start":{"line":187,"column":1,"offset":4918},"end":{"line":187,"column":82,"offset":4999},"indent":[]}}],"position":{"start":{"line":187,"column":1,"offset":4918},"end":{"line":187,"column":82,"offset":4999},"indent":[]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"1. Logistic Regression","position":{"start":{"line":189,"column":6,"offset":5006},"end":{"line":189,"column":28,"offset":5028},"indent":[]}}],"position":{"start":{"line":189,"column":1,"offset":5001},"end":{"line":189,"column":28,"offset":5028},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `from sklearn.linear_model import LogisticRegression\n \nLR = LogisticRegression()\nLR.fit(xv_train,y_train)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":191,"column":1,"offset":5030},"end":{"line":200,"column":13,"offset":5245},"indent":[1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Currently, we use the predefined model parameters. ","position":{"start":{"line":202,"column":1,"offset":5247},"end":{"line":202,"column":52,"offset":5298},"indent":[]}}],"position":{"start":{"line":202,"column":1,"offset":5247},"end":{"line":202,"column":52,"offset":5298},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `pred_lr=LR.predict(xv_test)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":204,"column":1,"offset":5300},"end":{"line":210,"column":13,"offset":5438},"indent":[1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Further on, we now try to find the score.","position":{"start":{"line":212,"column":1,"offset":5440},"end":{"line":212,"column":42,"offset":5481},"indent":[]}}],"position":{"start":{"line":212,"column":1,"offset":5440},"end":{"line":212,"column":42,"offset":5481},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `LR.score(xv_test, y_test)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":214,"column":1,"offset":5483},"end":{"line":220,"column":13,"offset":5619},"indent":[1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Lastly, let us take a look at the classification report:","position":{"start":{"line":222,"column":1,"offset":5621},"end":{"line":222,"column":57,"offset":5677},"indent":[]}}],"position":{"start":{"line":222,"column":1,"offset":5621},"end":{"line":222,"column":57,"offset":5677},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `print(classification_report(y_test,pred_lr))`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":224,"column":1,"offset":5679},"end":{"line":230,"column":13,"offset":5834},"indent":[1,1,1,1,1,1]}},{"type":"jsx","value":"<br />","position":{"start":{"line":232,"column":1,"offset":5836},"end":{"line":232,"column":7,"offset":5842},"indent":[]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"2. Decision Tree","position":{"start":{"line":234,"column":6,"offset":5849},"end":{"line":234,"column":22,"offset":5865},"indent":[]}}],"position":{"start":{"line":234,"column":1,"offset":5844},"end":{"line":234,"column":22,"offset":5865},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Performing similar modeling steps as above,","position":{"start":{"line":236,"column":1,"offset":5867},"end":{"line":236,"column":44,"offset":5910},"indent":[]}}],"position":{"start":{"line":236,"column":1,"offset":5867},"end":{"line":236,"column":44,"offset":5910},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `from sklearn.tree import DecisionTreeClassifier\n \nDT = DecisionTreeClassifier()\nDT.fit(xv_train, y_train)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":238,"column":1,"offset":5912},"end":{"line":247,"column":13,"offset":6128},"indent":[1,1,1,1,1,1,1,1,1]}},{"type":"jsx","value":"<br />","position":{"start":{"line":249,"column":1,"offset":6130},"end":{"line":249,"column":7,"offset":6136},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `pred_dt = DT.predict(xv_test)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />\n \n<br />","position":{"start":{"line":251,"column":1,"offset":6138},"end":{"line":259,"column":7,"offset":6287},"indent":[1,1,1,1,1,1,1,1]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `DT.score(xv_test, y_test)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":261,"column":1,"offset":6289},"end":{"line":267,"column":13,"offset":6425},"indent":[1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"We already see a slight improvement over Random Forest. The classification report of Decision tree is shown below:","position":{"start":{"line":269,"column":1,"offset":6427},"end":{"line":269,"column":115,"offset":6541},"indent":[]}}],"position":{"start":{"line":269,"column":1,"offset":6427},"end":{"line":269,"column":115,"offset":6541},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `print(classification_report(y_test, pred_dt))`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />\n<br />","position":{"start":{"line":271,"column":1,"offset":6543},"end":{"line":278,"column":7,"offset":6706},"indent":[1,1,1,1,1,1,1]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"3. Gradient boosting classifier","position":{"start":{"line":280,"column":6,"offset":6713},"end":{"line":280,"column":37,"offset":6744},"indent":[]}}],"position":{"start":{"line":280,"column":1,"offset":6708},"end":{"line":280,"column":37,"offset":6744},"indent":[]}},{"type":"jsx","value":"<br />","position":{"start":{"line":282,"column":1,"offset":6746},"end":{"line":282,"column":7,"offset":6752},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `from sklearn.ensemble import GradientBoostingClassifier\n \nGBC = GradientBoostingClassifier(random_state=0)\nGBC.fit(xv_train, y_train)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":284,"column":1,"offset":6754},"end":{"line":293,"column":13,"offset":6998},"indent":[1,1,1,1,1,1,1,1,1]}},{"type":"jsx","value":"<br />","position":{"start":{"line":295,"column":1,"offset":7000},"end":{"line":295,"column":7,"offset":7006},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `pred_gbc = GBC.predict(xv_test)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":297,"column":1,"offset":7008},"end":{"line":303,"column":13,"offset":7150},"indent":[1,1,1,1,1,1]}},{"type":"jsx","value":"<br />","position":{"start":{"line":305,"column":1,"offset":7152},"end":{"line":305,"column":7,"offset":7158},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `GBC.score(xv_test, y_test)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":307,"column":1,"offset":7160},"end":{"line":313,"column":13,"offset":7297},"indent":[1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"The score of the gradient boosting classifier is similar to that of the decision tree. Let us look at the classification report to find more:","position":{"start":{"line":315,"column":1,"offset":7299},"end":{"line":315,"column":142,"offset":7440},"indent":[]}}],"position":{"start":{"line":315,"column":1,"offset":7299},"end":{"line":315,"column":142,"offset":7440},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `print(classification_report(y_test, pred_gbc))`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />\n \n<br />","position":{"start":{"line":318,"column":1,"offset":7443},"end":{"line":326,"column":7,"offset":7609},"indent":[1,1,1,1,1,1,1,1]}},{"type":"heading","depth":4,"children":[{"type":"text","value":"4. Random Forest","position":{"start":{"line":328,"column":6,"offset":7616},"end":{"line":328,"column":22,"offset":7632},"indent":[]}}],"position":{"start":{"line":328,"column":1,"offset":7611},"end":{"line":328,"column":22,"offset":7632},"indent":[]}},{"type":"jsx","value":"<br />","position":{"start":{"line":330,"column":1,"offset":7634},"end":{"line":330,"column":7,"offset":7640},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `from sklearn.ensemble import RandomForestClassifier\n \nRFC = RandomForestClassifier(random_state=0)\nRFC.fit(xv_train, y_train)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":332,"column":1,"offset":7642},"end":{"line":341,"column":13,"offset":7878},"indent":[1,1,1,1,1,1,1,1,1]}},{"type":"jsx","value":"<br />","position":{"start":{"line":343,"column":1,"offset":7880},"end":{"line":343,"column":7,"offset":7886},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `pred_rfc = RFC.predict(xv_test)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":345,"column":1,"offset":7888},"end":{"line":351,"column":13,"offset":8030},"indent":[1,1,1,1,1,1]}},{"type":"jsx","value":"<br />","position":{"start":{"line":353,"column":1,"offset":8032},"end":{"line":353,"column":7,"offset":8038},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `RFC.score(xv_test, y_test)`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":355,"column":1,"offset":8040},"end":{"line":361,"column":13,"offset":8177},"indent":[1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"As noticed, Random forest outperforms all the above models. Checking the classification report below:","position":{"start":{"line":363,"column":1,"offset":8179},"end":{"line":363,"column":102,"offset":8280},"indent":[]}}],"position":{"start":{"line":363,"column":1,"offset":8179},"end":{"line":363,"column":102,"offset":8280},"indent":[]}},{"type":"jsx","value":"<CopyBlock\nlanguage={\"python\"}\ntext={ `print(classification_report(y_test, pred_rfc))`}\nshowLineNumbers={false}\ntheme={dracula}\nwrapLines={true}\ncodeBlock />","position":{"start":{"line":366,"column":1,"offset":8283},"end":{"line":372,"column":13,"offset":8440},"indent":[1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Now that we have trained different models, we can use them for evaluation on unseen or new data. You can find the complete code on the notebook here: ","position":{"start":{"line":375,"column":1,"offset":8443},"end":{"line":375,"column":151,"offset":8593},"indent":[]}}],"position":{"start":{"line":375,"column":1,"offset":8443},"end":{"line":375,"column":151,"offset":8593},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Please note the models can be further improved by changing their hyperparameters. You can also experiment with considering both the titles and text for detecting fake news. The possibilities are endless. ","position":{"start":{"line":377,"column":1,"offset":8595},"end":{"line":377,"column":205,"offset":8799},"indent":[]}}],"position":{"start":{"line":377,"column":1,"offset":8595},"end":{"line":377,"column":205,"offset":8799},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"I hope this notebook was of help. Do let me know if you have any questions or used different methods to train your model. ","position":{"start":{"line":380,"column":1,"offset":8802},"end":{"line":380,"column":123,"offset":8924},"indent":[]}}],"position":{"start":{"line":380,"column":1,"offset":8802},"end":{"line":380,"column":123,"offset":8924},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"the ","position":{"start":{"line":383,"column":1,"offset":8927},"end":{"line":383,"column":5,"offset":8931},"indent":[]}},{"type":"link","title":null,"url":"http://p.amxe.net/yh7n10br--ek1b5bf7-xrn","children":[{"type":"text","value":"repository","position":{"start":{"line":383,"column":6,"offset":8932},"end":{"line":383,"column":16,"offset":8942},"indent":[]}}],"position":{"start":{"line":383,"column":5,"offset":8931},"end":{"line":383,"column":59,"offset":8985},"indent":[]}},{"type":"text","value":" ","position":{"start":{"line":383,"column":59,"offset":8985},"end":{"line":383,"column":60,"offset":8986},"indent":[]}}],"position":{"start":{"line":383,"column":1,"offset":8927},"end":{"line":383,"column":60,"offset":8986},"indent":[]}},{"type":"export","value":"export const _frontmatter = {\"title\":\"Using NLP to detect Fake news!\",\"date\":\"2020-08-02T00:00:00.000Z\",\"info\":\"Develop a machine learning model to identify when an article might be fake news.\"}","position":{"start":{"line":388,"column":1,"offset":8991},"end":{"line":388,"column":195,"offset":9185},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":388,"column":195,"offset":9185}}},"scopeImports":["import { CopyBlock, dracula } from \"react-code-blocks\";","import * as React from 'react'"],"scopeIdentifiers":["CopyBlock","dracula","React"],"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Using NLP to detect Fake news!\",\n  \"date\": \"2020-08-02T00:00:00.000Z\",\n  \"info\": \"Develop a machine learning model to identify when an article might be fake news.\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", {\n    \"id\": \"detecting-fake-news\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h1\",\n    \"href\": \"#detecting-fake-news\",\n    \"aria-label\": \"detecting fake news permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Detecting Fake news\"), mdx(\"p\", null, \"Data has become the center of today\\u2019s\\u2019 businesses. In this modern world, 1.7 megaBytes data is generated per second. Many technologies have evolved to use this massive data for a better world. Machine learning is one of them and today we plan to use it to detect fake news. \"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"650px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/53106169f89ae7a2596d26f9b367846b/12609/fake.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"100%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBAH/xAAXAQADAQAAAAAAAAAAAAAAAAAAAgMB/9oADAMBAAIQAxAAAAHZ2deNhXrLurJkg0f/xAAcEAACAgIDAAAAAAAAAAAAAAAAAQIDBBESISL/2gAIAQEAAQUC22euLyIsmtPbKoVyhaJdM//EABcRAAMBAAAAAAAAAAAAAAAAAAABEBL/2gAIAQMBAT8BNKM//8QAGREAAgMBAAAAAAAAAAAAAAAAAAECITEy/9oACAECAQE/AROhckcP/8QAHhAAAQQBBQAAAAAAAAAAAAAAAAEREiECEBMxYqH/2gAIAQEABj8CyOsbKXw4IrY+3EQfT//EABwQAAIDAAMBAAAAAAAAAAAAAAERACExQVFhcf/aAAgBAQABPyGtKCNR9CF8whuIJ7euYRNgK0Nj4EnjMIgX5gjRc1P/2gAMAwEAAgADAAAAEPPvff/EABkRAQEAAwEAAAAAAAAAAAAAAAEAESExcf/aAAgBAwEBPxAy7knDHXy6v//EABkRAAIDAQAAAAAAAAAAAAAAAAABESExcf/aAAgBAgEBPxCJSaK1GHTM/8QAHhABAAICAwADAAAAAAAAAAAAAQARIUExUXFhofH/2gAIAQEAAT8QxQFZBzj8jltULcrNMsjBh0HYfEpKkRQ7cfqDhGkB333wS1WKyh7EETe/kCMN3PizoAvqf//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"fake news\",\n    \"title\": \"fake news\",\n    \"src\": \"/static/53106169f89ae7a2596d26f9b367846b/6aca1/fake.jpg\",\n    \"srcSet\": [\"/static/53106169f89ae7a2596d26f9b367846b/d2f63/fake.jpg 163w\", \"/static/53106169f89ae7a2596d26f9b367846b/c989d/fake.jpg 325w\", \"/static/53106169f89ae7a2596d26f9b367846b/6aca1/fake.jpg 650w\", \"/static/53106169f89ae7a2596d26f9b367846b/7c09c/fake.jpg 975w\", \"/static/53106169f89ae7a2596d26f9b367846b/01ab0/fake.jpg 1300w\", \"/static/53106169f89ae7a2596d26f9b367846b/12609/fake.jpg 3000w\"],\n    \"sizes\": \"(max-width: 650px) 100vw, 650px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"h2\", {\n    \"id\": \"what-exactly-is-fake-news\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#what-exactly-is-fake-news\",\n    \"aria-label\": \"what exactly is fake news permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"What exactly is fake news?\"), mdx(\"p\", null, \"Fake news is pieces of misinformation that are often incorporated to mislead people. Fake news is easy to spread as it carries no verification evidence.  This is often done to further or impose certain ideas and is often achieved with political agendas.\"), mdx(\"h2\", {\n    \"id\": \"how-do-we-plan-to-solve-it\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h2\",\n    \"href\": \"#how-do-we-plan-to-solve-it\",\n    \"aria-label\": \"how do we plan to solve it permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"How do we plan to solve it?\"), mdx(\"p\", null, \"This project is broken down into 5 steps, namely:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Loading the data\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Format the data\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Tokenize the data\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Build our model \"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Train multiple models\")), mdx(\"p\", null, \"Let us get started on detecting the fake news!\"), mdx(\"h3\", {\n    \"id\": \"loading-the-data\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#loading-the-data\",\n    \"aria-label\": \"loading the data permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Loading the Data\"), mdx(\"p\", null, \"I have used the \\u201CFake or Real News Dataset\\u201D from Kaggle. < link here>.\\nThe dataset comprises 2 csv files, namely fake and true. Both the files are available on kaggle for download. \"), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \" df_fake = pd.read_csv('Fake.csv')\\ndf_true = pd.read_csv('True.csv') \",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"The initial step would be to merge both the files to have one single file for both train and testing. However, before merging we need to add labels to it. We consider 1 for True and 0 for False. We introduce a new column called \\u2018class\\u2019.\"), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"df_fake['class'] = 0\\ndf_true['class'] = 1  \",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"After doing that, we simply merge both the files.\"), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"df_merge = pd.concat([df_fake, df_true], axis =0 ) \",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"h3\", {\n    \"id\": \"format-the-data\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#format-the-data\",\n    \"aria-label\": \"format the data permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Format the data\"), mdx(\"p\", null, \"Data preprocessing is a vital step to build a good model. Let us see the columns we have : \"), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"df_merge.columns \",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"For simplicity, we remove the columns \\u201Ctitle\\u201D, \\u201Csubject\\u201D,\\u201Cdate\\u201D and retain the text and class column for further processing.\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"df = df_merge.drop([\\\"title\\\", \\\"subject\\\",\\\"date\\\"], axis = 1) \",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"Next we check for any null values,\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"df.isnull().sum() \",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"Great, we have no null values. Now let us replace the index column and have a cleaner dataset.\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"df.reset_index(inplace = True)\\ndf.drop([\\\"index\\\"], axis = 1, inplace = True)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"I have defined a function wordopt below that performs basic regex operations on the text columns and modifies text on the following parameters:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Removes URLs and website links.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Removes unwanted spacings.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Replaces punctuations with a single space.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Removes line spacings.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Converts words in its lowercase.\")), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"def wordopt(text):\\n    text = text.lower()\\n    text = re.sub('[.*?]', '', text)\\n    text = re.sub(\\\"\\\\W\\\",\\\" \\\",text) \\n    text = re.sub('https?://S+|www.S+', '', text)\\n    text = re.sub('<.*?>+', '', text)\\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\\n    text = re.sub('\\\\n', '', text)\\n    text = re.sub('w*dw*', '', text)    \\n    return text \",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"This function is then applied to our text column, \"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"df[\\\"text\\\"] = df[\\\"text\\\"].apply(wordopt)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"Before performing tokenization, we have one final step to do. Split the dataset into test and train. We consider having a 70 - 30 split.\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"x = df['text']\\ny = df['class']\\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3) \",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"h3\", {\n    \"id\": \"tokenize-the-data\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#tokenize-the-data\",\n    \"aria-label\": \"tokenize the data permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Tokenize the data\"), mdx(\"p\", null, \"We use TF IDF to convert the text input into vectors. The explanation of TF IDF is out of scope for this blog, however, you may refer to get a deeper understanding. We use sklearn library to perform the steps.\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"from sklearn.feature_extraction.text import TfidfVectorizer\\n \\nvectorization = TfidfVectorizer()\\nxv_train = vectorization.fit_transform(x_train)\\nxv_test = vectorization.transform(x_test) \",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"Now, that we have the tokenized data, let\\u2019s build our first model.\"), mdx(\"h3\", {\n    \"id\": \"building-the-model\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#building-the-model\",\n    \"aria-label\": \"building the model permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"Building the Model\"), mdx(\"p\", null, \"We plan to build 4 different models and then compare them to choose the best one.\"), mdx(\"h4\", {\n    \"id\": \"1-logistic-regression\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#1-logistic-regression\",\n    \"aria-label\": \"1 logistic regression permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"1. Logistic Regression\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"from sklearn.linear_model import LogisticRegression\\n \\nLR = LogisticRegression()\\nLR.fit(xv_train,y_train)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"Currently, we use the predefined model parameters. \"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"pred_lr=LR.predict(xv_test)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"Further on, we now try to find the score.\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"LR.score(xv_test, y_test)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"Lastly, let us take a look at the classification report:\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"print(classification_report(y_test,pred_lr))\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"br\", null), mdx(\"h4\", {\n    \"id\": \"2-decision-tree\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#2-decision-tree\",\n    \"aria-label\": \"2 decision tree permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"2. Decision Tree\"), mdx(\"p\", null, \"Performing similar modeling steps as above,\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"from sklearn.tree import DecisionTreeClassifier\\n \\nDT = DecisionTreeClassifier()\\nDT.fit(xv_train, y_train)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"pred_dt = DT.predict(xv_test)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"DT.score(xv_test, y_test)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"We already see a slight improvement over Random Forest. The classification report of Decision tree is shown below:\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"print(classification_report(y_test, pred_dt))\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"br\", null), mdx(\"h4\", {\n    \"id\": \"3-gradient-boosting-classifier\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#3-gradient-boosting-classifier\",\n    \"aria-label\": \"3 gradient boosting classifier permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"3. Gradient boosting classifier\"), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"from sklearn.ensemble import GradientBoostingClassifier\\n \\nGBC = GradientBoostingClassifier(random_state=0)\\nGBC.fit(xv_train, y_train)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"pred_gbc = GBC.predict(xv_test)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"GBC.score(xv_test, y_test)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"The score of the gradient boosting classifier is similar to that of the decision tree. Let us look at the classification report to find more:\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"print(classification_report(y_test, pred_gbc))\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"br\", null), mdx(\"h4\", {\n    \"id\": \"4-random-forest\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#4-random-forest\",\n    \"aria-label\": \"4 random forest permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }, mdx(\"path\", {\n    parentName: \"svg\",\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  }))), \"4. Random Forest\"), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"from sklearn.ensemble import RandomForestClassifier\\n \\nRFC = RandomForestClassifier(random_state=0)\\nRFC.fit(xv_train, y_train)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"pred_rfc = RFC.predict(xv_test)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"br\", null), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"RFC.score(xv_test, y_test)\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"As noticed, Random forest outperforms all the above models. Checking the classification report below:\"), mdx(CopyBlock, {\n    language: \"python\",\n    text: \"print(classification_report(y_test, pred_rfc))\",\n    showLineNumbers: false,\n    theme: dracula,\n    wrapLines: true,\n    codeBlock: true,\n    mdxType: \"CopyBlock\"\n  }), mdx(\"p\", null, \"Now that we have trained different models, we can use them for evaluation on unseen or new data. You can find the complete code on the notebook here: \"), mdx(\"p\", null, \"Please note the models can be further improved by changing their hyperparameters. You can also experiment with considering both the titles and text for detecting fake news. The possibilities are endless. \"), mdx(\"p\", null, \"I hope this notebook was of help. Do let me know if you have any questions or used different methods to train your model. \"), mdx(\"p\", null, \"the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://p.amxe.net/yh7n10br--ek1b5bf7-xrn\"\n  }, \"repository\"), \" \"));\n}\n;\nMDXContent.isMDXComponent = true;","rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsxRuntime classic */\n/* @jsx mdx */\nimport { CopyBlock, dracula } from \"react-code-blocks\";\nexport const _frontmatter = {\n  \"title\": \"Using NLP to detect Fake news!\",\n  \"date\": \"2020-08-02T00:00:00.000Z\",\n  \"info\": \"Develop a machine learning model to identify when an article might be fake news.\"\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n    <h1 {...{\n      \"id\": \"detecting-fake-news\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h1\" {...{\n        \"href\": \"#detecting-fake-news\",\n        \"aria-label\": \"detecting fake news permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`Detecting Fake news`}</h1>\n    <p>{`Data has become the center of today’s’ businesses. In this modern world, 1.7 megaBytes data is generated per second. Many technologies have evolved to use this massive data for a better world. Machine learning is one of them and today we plan to use it to detect fake news. `}</p>\n    <p><span parentName=\"p\" {...{\n        \"className\": \"gatsby-resp-image-wrapper\",\n        \"style\": {\n          \"position\": \"relative\",\n          \"display\": \"block\",\n          \"marginLeft\": \"auto\",\n          \"marginRight\": \"auto\",\n          \"maxWidth\": \"650px\"\n        }\n      }}>{`\n      `}<a parentName=\"span\" {...{\n          \"className\": \"gatsby-resp-image-link\",\n          \"href\": \"/static/53106169f89ae7a2596d26f9b367846b/12609/fake.jpg\",\n          \"style\": {\n            \"display\": \"block\"\n          },\n          \"target\": \"_blank\",\n          \"rel\": \"noopener\"\n        }}>{`\n    `}<span parentName=\"a\" {...{\n            \"className\": \"gatsby-resp-image-background-image\",\n            \"style\": {\n              \"paddingBottom\": \"100%\",\n              \"position\": \"relative\",\n              \"bottom\": \"0\",\n              \"left\": \"0\",\n              \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAIDBAH/xAAXAQADAQAAAAAAAAAAAAAAAAAAAgMB/9oADAMBAAIQAxAAAAHZ2deNhXrLurJkg0f/xAAcEAACAgIDAAAAAAAAAAAAAAAAAQIDBBESISL/2gAIAQEAAQUC22euLyIsmtPbKoVyhaJdM//EABcRAAMBAAAAAAAAAAAAAAAAAAABEBL/2gAIAQMBAT8BNKM//8QAGREAAgMBAAAAAAAAAAAAAAAAAAECITEy/9oACAECAQE/AROhckcP/8QAHhAAAQQBBQAAAAAAAAAAAAAAAAEREiECEBMxYqH/2gAIAQEABj8CyOsbKXw4IrY+3EQfT//EABwQAAIDAAMBAAAAAAAAAAAAAAERACExQVFhcf/aAAgBAQABPyGtKCNR9CF8whuIJ7euYRNgK0Nj4EnjMIgX5gjRc1P/2gAMAwEAAgADAAAAEPPvff/EABkRAQEAAwEAAAAAAAAAAAAAAAEAESExcf/aAAgBAwEBPxAy7knDHXy6v//EABkRAAIDAQAAAAAAAAAAAAAAAAABESExcf/aAAgBAgEBPxCJSaK1GHTM/8QAHhABAAICAwADAAAAAAAAAAAAAQARIUExUXFhofH/2gAIAQEAAT8QxQFZBzj8jltULcrNMsjBh0HYfEpKkRQ7cfqDhGkB333wS1WKyh7EETe/kCMN3PizoAvqf//Z')\",\n              \"backgroundSize\": \"cover\",\n              \"display\": \"block\"\n            }\n          }}></span>{`\n  `}<img parentName=\"a\" {...{\n            \"className\": \"gatsby-resp-image-image\",\n            \"alt\": \"fake news\",\n            \"title\": \"fake news\",\n            \"src\": \"/static/53106169f89ae7a2596d26f9b367846b/6aca1/fake.jpg\",\n            \"srcSet\": [\"/static/53106169f89ae7a2596d26f9b367846b/d2f63/fake.jpg 163w\", \"/static/53106169f89ae7a2596d26f9b367846b/c989d/fake.jpg 325w\", \"/static/53106169f89ae7a2596d26f9b367846b/6aca1/fake.jpg 650w\", \"/static/53106169f89ae7a2596d26f9b367846b/7c09c/fake.jpg 975w\", \"/static/53106169f89ae7a2596d26f9b367846b/01ab0/fake.jpg 1300w\", \"/static/53106169f89ae7a2596d26f9b367846b/12609/fake.jpg 3000w\"],\n            \"sizes\": \"(max-width: 650px) 100vw, 650px\",\n            \"style\": {\n              \"width\": \"100%\",\n              \"height\": \"100%\",\n              \"margin\": \"0\",\n              \"verticalAlign\": \"middle\",\n              \"position\": \"absolute\",\n              \"top\": \"0\",\n              \"left\": \"0\"\n            },\n            \"loading\": \"lazy\"\n          }}></img>{`\n  `}</a>{`\n    `}</span></p>\n    <h2 {...{\n      \"id\": \"what-exactly-is-fake-news\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h2\" {...{\n        \"href\": \"#what-exactly-is-fake-news\",\n        \"aria-label\": \"what exactly is fake news permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`What exactly is fake news?`}</h2>\n    <p>{`Fake news is pieces of misinformation that are often incorporated to mislead people. Fake news is easy to spread as it carries no verification evidence.  This is often done to further or impose certain ideas and is often achieved with political agendas.`}</p>\n    <h2 {...{\n      \"id\": \"how-do-we-plan-to-solve-it\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h2\" {...{\n        \"href\": \"#how-do-we-plan-to-solve-it\",\n        \"aria-label\": \"how do we plan to solve it permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`How do we plan to solve it?`}</h2>\n    <p>{`This project is broken down into 5 steps, namely:`}</p>\n    <ol>\n      <li parentName=\"ol\">{`Loading the data`}</li>\n      <li parentName=\"ol\">{`Format the data`}</li>\n      <li parentName=\"ol\">{`Tokenize the data`}</li>\n      <li parentName=\"ol\">{`Build our model `}</li>\n      <li parentName=\"ol\">{`Train multiple models`}</li>\n    </ol>\n    <p>{`Let us get started on detecting the fake news!`}</p>\n    <h3 {...{\n      \"id\": \"loading-the-data\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h3\" {...{\n        \"href\": \"#loading-the-data\",\n        \"aria-label\": \"loading the data permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`Loading the Data`}</h3>\n    <p>{`I have used the “Fake or Real News Dataset” from Kaggle. < link here>.\nThe dataset comprises 2 csv files, namely fake and true. Both the files are available on kaggle for download. `}</p>\n    <br />\n    <CopyBlock language={\"python\"} text={` df_fake = pd.read_csv('Fake.csv')\ndf_true = pd.read_csv('True.csv') `} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`The initial step would be to merge both the files to have one single file for both train and testing. However, before merging we need to add labels to it. We consider 1 for True and 0 for False. We introduce a new column called ‘class’.`}</p>\n    <br />\n    <CopyBlock language={\"python\"} text={`df_fake['class'] = 0\ndf_true['class'] = 1  `} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`After doing that, we simply merge both the files.`}</p>\n    <br />\n    <CopyBlock language={\"python\"} text={`df_merge = pd.concat([df_fake, df_true], axis =0 ) `} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <h3 {...{\n      \"id\": \"format-the-data\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h3\" {...{\n        \"href\": \"#format-the-data\",\n        \"aria-label\": \"format the data permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`Format the data`}</h3>\n    <p>{`Data preprocessing is a vital step to build a good model. Let us see the columns we have : `}</p>\n    <br />\n    <CopyBlock language={\"python\"} text={`df_merge.columns `} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`For simplicity, we remove the columns “title”, “subject”,“date” and retain the text and class column for further processing.`}</p>\n    <CopyBlock language={\"python\"} text={`df = df_merge.drop([\"title\", \"subject\",\"date\"], axis = 1) `} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`Next we check for any null values,`}</p>\n    <CopyBlock language={\"python\"} text={`df.isnull().sum() `} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`Great, we have no null values. Now let us replace the index column and have a cleaner dataset.`}</p>\n    <CopyBlock language={\"python\"} text={`df.reset_index(inplace = True)\ndf.drop([\"index\"], axis = 1, inplace = True)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`I have defined a function wordopt below that performs basic regex operations on the text columns and modifies text on the following parameters:`}</p>\n    <ol>\n      <li parentName=\"ol\">{`Removes URLs and website links.`}</li>\n      <li parentName=\"ol\">{`Removes unwanted spacings.`}</li>\n      <li parentName=\"ol\">{`Replaces punctuations with a single space.`}</li>\n      <li parentName=\"ol\">{`Removes line spacings.`}</li>\n      <li parentName=\"ol\">{`Converts words in its lowercase.`}</li>\n    </ol>\n    <CopyBlock language={\"python\"} text={`def wordopt(text):\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub(\"\\\\W\",\" \",text) \n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)    \n    return text `} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`This function is then applied to our text column, `}</p>\n    <CopyBlock language={\"python\"} text={`df[\"text\"] = df[\"text\"].apply(wordopt)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`Before performing tokenization, we have one final step to do. Split the dataset into test and train. We consider having a 70 - 30 split.`}</p>\n    <CopyBlock language={\"python\"} text={`x = df['text']\ny = df['class']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3) `} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <h3 {...{\n      \"id\": \"tokenize-the-data\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h3\" {...{\n        \"href\": \"#tokenize-the-data\",\n        \"aria-label\": \"tokenize the data permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`Tokenize the data`}</h3>\n    <p>{`We use TF IDF to convert the text input into vectors. The explanation of TF IDF is out of scope for this blog, however, you may refer to get a deeper understanding. We use sklearn library to perform the steps.`}</p>\n    <CopyBlock language={\"python\"} text={`from sklearn.feature_extraction.text import TfidfVectorizer\n \nvectorization = TfidfVectorizer()\nxv_train = vectorization.fit_transform(x_train)\nxv_test = vectorization.transform(x_test) `} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`Now, that we have the tokenized data, let’s build our first model.`}</p>\n    <h3 {...{\n      \"id\": \"building-the-model\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h3\" {...{\n        \"href\": \"#building-the-model\",\n        \"aria-label\": \"building the model permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`Building the Model`}</h3>\n    <p>{`We plan to build 4 different models and then compare them to choose the best one.`}</p>\n    <h4 {...{\n      \"id\": \"1-logistic-regression\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h4\" {...{\n        \"href\": \"#1-logistic-regression\",\n        \"aria-label\": \"1 logistic regression permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`1. Logistic Regression`}</h4>\n    <CopyBlock language={\"python\"} text={`from sklearn.linear_model import LogisticRegression\n \nLR = LogisticRegression()\nLR.fit(xv_train,y_train)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`Currently, we use the predefined model parameters. `}</p>\n    <CopyBlock language={\"python\"} text={`pred_lr=LR.predict(xv_test)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`Further on, we now try to find the score.`}</p>\n    <CopyBlock language={\"python\"} text={`LR.score(xv_test, y_test)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`Lastly, let us take a look at the classification report:`}</p>\n    <CopyBlock language={\"python\"} text={`print(classification_report(y_test,pred_lr))`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <br />\n    <h4 {...{\n      \"id\": \"2-decision-tree\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h4\" {...{\n        \"href\": \"#2-decision-tree\",\n        \"aria-label\": \"2 decision tree permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`2. Decision Tree`}</h4>\n    <p>{`Performing similar modeling steps as above,`}</p>\n    <CopyBlock language={\"python\"} text={`from sklearn.tree import DecisionTreeClassifier\n \nDT = DecisionTreeClassifier()\nDT.fit(xv_train, y_train)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <br />\n    <CopyBlock language={\"python\"} text={`pred_dt = DT.predict(xv_test)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n \n    <br />\n    <CopyBlock language={\"python\"} text={`DT.score(xv_test, y_test)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`We already see a slight improvement over Random Forest. The classification report of Decision tree is shown below:`}</p>\n    <CopyBlock language={\"python\"} text={`print(classification_report(y_test, pred_dt))`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <br />\n    <h4 {...{\n      \"id\": \"3-gradient-boosting-classifier\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h4\" {...{\n        \"href\": \"#3-gradient-boosting-classifier\",\n        \"aria-label\": \"3 gradient boosting classifier permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`3. Gradient boosting classifier`}</h4>\n    <br />\n    <CopyBlock language={\"python\"} text={`from sklearn.ensemble import GradientBoostingClassifier\n \nGBC = GradientBoostingClassifier(random_state=0)\nGBC.fit(xv_train, y_train)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <br />\n    <CopyBlock language={\"python\"} text={`pred_gbc = GBC.predict(xv_test)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <br />\n    <CopyBlock language={\"python\"} text={`GBC.score(xv_test, y_test)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`The score of the gradient boosting classifier is similar to that of the decision tree. Let us look at the classification report to find more:`}</p>\n    <CopyBlock language={\"python\"} text={`print(classification_report(y_test, pred_gbc))`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n \n    <br />\n    <h4 {...{\n      \"id\": \"4-random-forest\",\n      \"style\": {\n        \"position\": \"relative\"\n      }\n    }}><a parentName=\"h4\" {...{\n        \"href\": \"#4-random-forest\",\n        \"aria-label\": \"4 random forest permalink\",\n        \"className\": \"anchor before\"\n      }}><svg parentName=\"a\" {...{\n          \"aria-hidden\": \"true\",\n          \"focusable\": \"false\",\n          \"height\": \"16\",\n          \"version\": \"1.1\",\n          \"viewBox\": \"0 0 16 16\",\n          \"width\": \"16\"\n        }}><path parentName=\"svg\" {...{\n            \"fillRule\": \"evenodd\",\n            \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n          }}></path></svg></a>{`4. Random Forest`}</h4>\n    <br />\n    <CopyBlock language={\"python\"} text={`from sklearn.ensemble import RandomForestClassifier\n \nRFC = RandomForestClassifier(random_state=0)\nRFC.fit(xv_train, y_train)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <br />\n    <CopyBlock language={\"python\"} text={`pred_rfc = RFC.predict(xv_test)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <br />\n    <CopyBlock language={\"python\"} text={`RFC.score(xv_test, y_test)`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`As noticed, Random forest outperforms all the above models. Checking the classification report below:`}</p>\n    <CopyBlock language={\"python\"} text={`print(classification_report(y_test, pred_rfc))`} showLineNumbers={false} theme={dracula} wrapLines={true} codeBlock mdxType=\"CopyBlock\" />\n    <p>{`Now that we have trained different models, we can use them for evaluation on unseen or new data. You can find the complete code on the notebook here: `}</p>\n    <p>{`Please note the models can be further improved by changing their hyperparameters. You can also experiment with considering both the titles and text for detecting fake news. The possibilities are endless. `}</p>\n    <p>{`I hope this notebook was of help. Do let me know if you have any questions or used different methods to train your model. `}</p>\n    <p>{`the `}<a parentName=\"p\" {...{\n        \"href\": \"http://p.amxe.net/yh7n10br--ek1b5bf7-xrn\"\n      }}>{`repository`}</a>{` `}</p>\n\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}